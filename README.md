
# üöÄ Proyecto ML ‚Äì Arquitectura Modular con UI en Streamlit

Este repositorio contiene un flujo completo de **EDA ‚Üí Preprocesamiento ‚Üí Artefactos ML**, expuesto a trav√©s de una **UI interactiva en Streamlit** y estructurado seg√∫n una **arquitectura modular**.


## üì¶ 1) Descarga del proyecto

### Requisitos previos

- **Git**
- **Python 3.10+**

### Clonar el repositorio

```bash
git clone <URL_DEL_REPO>
cd EDA
```

> üí° Aseg√∫rate de estar en la carpeta ra√≠z del proyecto antes de continuar.


## üõ†Ô∏è 2) Configuraci√≥n b√°sica

### Crear y activar entorno virtual

```bash
python3 -m venv venv
source venv/bin/activate
# En Windows:
# venv\Scripts\activate
```

### Instalar dependencias

```bash
pip install -r requirements.txt
```


## üìÇ 3) Dataset y configuraci√≥n

### Ubicaci√≥n del dataset

Verifica que el archivo CSV est√© en:

```text
data/raw/TITULADO_2007-2024_web_19_05_2025_E.csv
```

### Configuraci√≥n actual

El archivo de configuraci√≥n principal es:

```text
config/config.py
```

All√≠ se definen, entre otros:

* Separador del CSV: `';'`
* *Encoding*: `'latin1'`

> ‚öôÔ∏è Si cambias el archivo de entrada o su formato, **ajusta estos par√°metros** en `config/config.py`.

### Objetivos del modelo

* **Clasificaci√≥n (`MODALIDAD_BIN`)**

  * Clase `1` ‚Üí **Presencial**
  * Clase `0` ‚Üí **No presencial / otras modalidades**

* **Regresi√≥n (`PROMEDIO_EDAD_PROGRAMA`)**

  * Variable continua de edad promedio por programa.



## üéõÔ∏è 4) Ejecutar la UI (Streamlit)

### Lanzar la aplicaci√≥n

```bash
streamlit run ui/app.py
```

### Secciones disponibles en la UI

* **Fase 1 ‚Äì Configuraci√≥n inicial**

  * Validar objetivos (`MODALIDAD_BIN`, `PROMEDIO_EDAD_PROGRAMA`).
  * Verificar ruta y par√°metros de lectura del dataset.

* **Fase 2 ‚Äì EDA (An√°lisis Exploratorio de Datos)**

  * Carga del dataset.
  * Ejecuci√≥n del EDA automatizado.
  * Visualizaci√≥n de artefactos generados (`.csv`, `.png`) con su ruta correspondiente.

* **Fase 3 ‚Äì Preprocesamiento**

  * Limpieza de datos.
  * *Split* temporal.
  * Escalado con **StandardScaler**.
  * Codificaci√≥n segura de variables categ√≥ricas:

    * **One-Hot Encoding (OHE)** con *rare grouping* / *frequency encoding*.
  * Generaci√≥n y c√°lculo de *features*:

    * **HHI**
    * **LQ**
    * **IPG**
  * C√°lculo optimizado de:

    * **Matriz de correlaci√≥n**
    * **VIF (Variance Inflation Factor)**
  * Selecci√≥n de variables y guardado de resultados.

* **Fase 4 ‚Äì Interpretabilidad (XAI)**

  * Entrena un modelo demo (RandomForest/Logistic/Linear) sobre train.
  * Explicabilidad: Feature Importance (√°rbol), Permutation Importance y Coeficientes lineales.
  * Guarda artefactos en `reports/*.csv` y muestra tablas/gr√°ficos en la UI.

* **Informes**

  * Pesta√±as que renderizan todos los `.md` dentro de `docs/`.

* **Bot√≥n lateral**

  * **"Limpiar artefactos (clean.sh)"**
    Permite reiniciar la salida del proyecto sin modificar los datos crudos en `data/raw`.


## üìÅ 5) Artefactos generados

### EDA / Res√∫menes

* `outputs/eda/resumen/*`
  Incluye:

  * CSVs de resumen
  * `decision_metricas.txt`

### Gr√°ficos

* `outputs/eda/figures/*`
* Copias auxiliares en:

  * `data/processed/*.png`

### Correlaci√≥n / VIF

* `data/processed/correlation_matrix.csv`
* `data/processed/vif_scores.csv`
* Archivos auxiliares:

  * `*columns_used.txt` (columnas empleadas para los c√°lculos)

### Selecci√≥n de *features*

* `data/processed/selected_features.txt`

### Datasets finales

* `data/processed/X_train_engineered.csv`
* `data/processed/X_test_engineered.csv`

### Interpretabilidad (XAI)

* `reports/feature_importance_*.csv`
* `reports/permutation_importance_*.csv`
* `reports/coefficients_linear_*.csv`




## üß™ 6) Ejecuci√≥n desde CLI (flujo completo)

Si prefieres correr el flujo sin UI:

### 6.1 Activar entorno e instalar dependencias

```bash
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
```

### 6.2 Ejecutar flujo completo (EDA + preprocesamiento)

```bash
python scripts/run_all.py
```

### 6.3 Artefactos generados v√≠a CLI

* `data/processed/*`

  * Datasets procesados
  * Correlaci√≥n
  * VIF
  * *Features* seleccionadas

* `outputs/eda/resumen/*`

  * Res√∫menes de EDA y preprocesamiento


## üßæ 7) Notas y convenciones

* **ML** ‚Üí *Machine Learning* (Aprendizaje Autom√°tico)
* **OHE** ‚Üí *One-Hot Encoding*
* **VIF** ‚Üí *Variance Inflation Factor*

Si cambias los objetivos (`MODALIDAD_BIN` / `PROMEDIO_EDAD_PROGRAMA`), recuerda actualizar:

* `config/config.py`

### Script de limpieza: `clean.sh`

```bash
bash clean.sh
```

* Recrea la estructura de artefactos **vac√≠a**.
* **No modifica** el contenido de `data/raw`.

### Limitar uso de CPU en c√°lculos intensivos (opcional)

```bash
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
```


## ‚úÖ Resumen r√°pido

* Clona el repo y crea un entorno virtual.
* Ajusta `config/config.py` si cambias el dataset.
* Ejecuta la UI con `streamlit run ui/app.py` **o** usa `python scripts/run_all.py` desde CLI.
* Usa `clean.sh` para resetear artefactos sin tocar los datos crudos.



