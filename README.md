
# üöÄ Proyecto ML ‚Äì Arquitectura Modular con UI en Streamlit

Este repositorio contiene un flujo completo de **EDA ‚Üí Preprocesamiento ‚Üí Artefactos ML**, expuesto a trav√©s de una **UI interactiva en Streamlit** y estructurado seg√∫n una **arquitectura modular**.


## üì¶ 1) Descarga del proyecto

### Requisitos previos

- **Git**
- **Python 3.10+**

### Clonar el repositorio

```bash
git clone <URL_DEL_REPO>
cd EDA
```

> üí° Aseg√∫rate de estar en la carpeta ra√≠z del proyecto antes de continuar.


## üõ†Ô∏è 2) Configuraci√≥n b√°sica

### Crear y activar entorno virtual

```bash
python3 -m venv venv
source venv/bin/activate
# En Windows:
# venv\Scripts\activate
```

### Instalar dependencias

```bash
pip install -r requirements.txt
```


## üìÇ 3) Dataset y configuraci√≥n

### Ubicaci√≥n del dataset

Verifica que el archivo CSV est√© en:

```text
data/raw/TITULADO_2007-2024_web_19_05_2025_E.csv
```

### Configuraci√≥n actual

El archivo de configuraci√≥n principal es:

```text
config/config.py
```

All√≠ se definen, entre otros:

* Separador del CSV: `';'`
* *Encoding*: `'latin1'`

> ‚öôÔ∏è Si cambias el archivo de entrada o su formato, **ajusta estos par√°metros** en `config/config.py`.

### Objetivos del modelo

* **Clasificaci√≥n (`MODALIDAD_BIN`)**

  * Clase `1` ‚Üí **Presencial**
  * Clase `0` ‚Üí **No presencial / otras modalidades**

* **Regresi√≥n (`PROMEDIO_EDAD_PROGRAMA`)**

  * Variable continua de edad promedio por programa.



## üéõÔ∏è 4) Ejecutar la UI (Streamlit)

### Lanzar la aplicaci√≥n

```bash
streamlit run ui/app.py
```

### Secciones disponibles en la UI

* **Fase 1 ‚Äì Configuraci√≥n inicial**

  * Validar objetivos (`MODALIDAD_BIN`, `PROMEDIO_EDAD_PROGRAMA`).
  * Verificar ruta y par√°metros de lectura del dataset.

* **Fase 2 ‚Äì EDA (An√°lisis Exploratorio de Datos)**

  * Carga del dataset.
  * Ejecuci√≥n del EDA automatizado.
  * Visualizaci√≥n de artefactos generados (`.csv`, `.png`) con su ruta correspondiente.

* **Fase 3 ‚Äì Preprocesamiento**

  * Limpieza de datos.
  * *Split* temporal.
  * Escalado con **StandardScaler**.
  * Codificaci√≥n segura de variables categ√≥ricas:

    * **One-Hot Encoding (OHE)** con *rare grouping* / *frequency encoding*.
  * Generaci√≥n y c√°lculo de *features*:

    * **HHI**
    * **LQ**
    * **IPG**
  * C√°lculo optimizado de:

    * **Matriz de correlaci√≥n**
    * **VIF (Variance Inflation Factor)**
  * Selecci√≥n de variables y guardado de resultados.

* **Fase 4 ‚Äì Interpretabilidad (XAI)**

  * Entrena un modelo demo (RandomForest/Logistic/Linear) sobre train.
  * Explicabilidad: Feature Importance (√°rbol), Permutation Importance y Coeficientes lineales.
  * Guarda artefactos en `reports/*.csv` y muestra tablas/gr√°ficos en la UI.

* **Informes**

  * Pesta√±as que renderizan todos los `.md` dentro de `docs/`.

* **Bot√≥n lateral**

  * **"Limpiar artefactos (clean.sh)"**
    Permite reiniciar la salida del proyecto sin modificar los datos crudos en `data/raw`.


## üìÅ 5) Artefactos generados

### EDA / Res√∫menes

* `outputs/eda/resumen/*`
  Incluye:

  * CSVs de resumen
  * `decision_metricas.txt`

### Gr√°ficos

* `outputs/eda/figures/*`
* Copias auxiliares en:

  * `data/processed/*.png`

### Correlaci√≥n / VIF

* `data/processed/correlation_matrix.csv`
* `data/processed/vif_scores.csv`
* Archivos auxiliares:

  * `*columns_used.txt` (columnas empleadas para los c√°lculos)

### Selecci√≥n de *features*

* `data/processed/selected_features.txt`

### Datasets finales

* `data/processed/X_train_engineered.csv`
* `data/processed/X_test_engineered.csv`

### Interpretabilidad (XAI)

* `reports/feature_importance_*.csv`
* `reports/permutation_importance_*.csv`
* `reports/coefficients_linear_*.csv`




## üß™ 6) Ejecuci√≥n desde CLI (flujo completo)

Si prefieres correr el flujo sin UI:

### 6.1 Activar entorno e instalar dependencias

```bash
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
```

### 6.2 Ejecutar flujo completo (EDA + preprocesamiento)

```bash
python scripts/run_all.py
```

### 6.3 Artefactos generados v√≠a CLI

* `data/processed/*`

  * Datasets procesados
  * Correlaci√≥n
  * VIF
  * *Features* seleccionadas

* `outputs/eda/resumen/*`

  * Res√∫menes de EDA y preprocesamiento


## üßæ 7) Notas y convenciones

* **ML** ‚Üí *Machine Learning* (Aprendizaje Autom√°tico)
* **OHE** ‚Üí *One-Hot Encoding*
* **VIF** ‚Üí *Variance Inflation Factor*

Si cambias los objetivos (`MODALIDAD_BIN` / `PROMEDIO_EDAD_PROGRAMA`), recuerda actualizar:

* `config/config.py`

### Script de limpieza: `clean.sh`

```bash
bash clean.sh
```

* Recrea la estructura de artefactos **vac√≠a**.
* **No modifica** el contenido de `data/raw`.

### Limitar uso de CPU en c√°lculos intensivos (opcional)

```bash
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
```


## 8) Implementaci√≥n de oportunidad de mejora

### 8.1 Riesgo de fuga/tautolog√≠a
**Oportunidad**: Riesgo de fuga/tautolog√≠a al predecir `PROMEDIO EDAD PROGRAMA ` usando sus componentes directos (`PROMEDIO EDAD HOMBRE `, `PROMEDIO EDAD MUJER `), lo que podr√≠a inflar m√©tricas sin aportar se√±al nueva.
Implementaci√≥n: Se a√±adi√≥ detecci√≥n autom√°tica (regresi√≥n lineal simple) en `preprocess_pipeline` con limpieza robusta (strip, normalizaci√≥n decimal) y reporte `reports/leakage_report.json`. Estrategias soportadas en `config/params.yaml`: `drop_features`, `redefine_target`, `fail`. Umbral `r2_threshold=0.90` mantiene criterios estrictos; en los datos actuales R¬≤‚âà0.19 < 0.90 ‚áí no se aplica mitigaci√≥n.
C√≥mo ejecutar/prueba:
1. Flujo completo: `python scripts/run_all.py` (muestra resumen [LEAKAGE] en consola y genera `reports/leakage_report.json`).
2. Chequeo directo regresi√≥n: `python scripts/run_regression_leakage.py --strategy redefine_target` (fuerza lectura y pipeline; si R¬≤‚â•0.90 redefine y crea `outputs/metadata/target_mapping.json`).
3. Para probar mitigaciones: cambia `strategy` a `drop_features` o `redefine_target` y (opcional) ajusta temporalmente `r2_threshold` a un valor menor (ej. 0.05) para ver acci√≥n aplicada (`reports/leakage_action.txt`).
Timestamp actualizaci√≥n: 2025-11-20T01:56:36.110Z
 
---

### 8.2 Tuning expl√≠cito (HPO)
**Oportunidad**: originalmente el entrenamiento usaba hiperpar√°metros fijos en RandomForest, sin experimento sistem√°tico ni documentaci√≥n de la selecci√≥n √≥ptima. Se requer√≠a explorar `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf` con m√©todos Grid y Bayes y dejar trazabilidad.
Implementaci√≥n: se cre√≥ `scripts/run_hpo.py` con soporte para:
- GridSearchCV (`--method grid`) usando el espacio configurado en `config/params.yaml`.
- BayesSearchCV (`--method bayes`) para optimizaci√≥n m√°s eficiente.
- Tareas de regresi√≥n y clasificaci√≥n (`--task reg|clf`).
- Modo r√°pido (`--fast`) que reduce el grid / iteraciones para exploraci√≥n inicial.
- Submuestreo opcional `--max-samples` y control de n√∫cleos `--n-jobs`.
Artefactos generados:
- `outputs/hpo_<task>/results.csv` con todas las combinaciones y m√©tricas (`neg_mean_absolute_error`, `neg_root_mean_squared_error`, `r2` o `roc_auc`, `f1_macro`, `accuracy`).
- `outputs/hpo_<task>/best.json` con la mejor configuraci√≥n seg√∫n m√©trica de refit.
- `reports/hpo_summary.md` acumulando ejecuciones y mostrando Top 5 por m√©trica y bloque JSON de la mejor configuraci√≥n.
Integraci√≥n en flujo principal: bandera `--with-hpo` en `scripts/run_all.py` dispara HPO previo al entrenamiento y aplica autom√°ticamente `best_params` al modelo (clasificaci√≥n o regresi√≥n). Elegir m√©todo con `--hpo-method=grid|bayes`.
Comprobaci√≥n r√°pida:
```bash
# Grid regresi√≥n
python scripts/run_hpo.py --task reg --method grid --fast --out-dir outputs/hpo_reg_fast
# Bayes clasificaci√≥n
python scripts/run_hpo.py --task clf --method bayes --fast --bayes-iter 10 --out-dir outputs/hpo_clf_fast --no-leak-check
# Flujo completo con HPO (grid)
python scripts/run_all.py --with-hpo --hpo-method=grid
# Flujo completo con HPO (bayes)
python scripts/run_all.py --with-hpo --hpo-method=bayes
```
Validaci√≥n: inspeccionar `reports/hpo_summary.md` para tablas y `outputs/hpo_<task>/best.json` para par√°metros √≥ptimos aplicados. Reproducibilidad: ajustar semilla en `config/params.yaml` (`hpo.random_state`).

### 8.3 Validaci√≥n temporal (TimeSeriesSplit / split fijo)
**Oportunidad**: asegurar robustez temporal (evitar fuga hacia el futuro) cuando existe dimensi√≥n a√±o.
Implementaci√≥n: el split fijo est√° parametrizado en `config/config.py` (train ‚â§2018, gap 2019, test 2020‚Äì2024) y se aplica en `src/preprocessing/clean.py::temporal_split`. Adem√°s, el CV temporal est√° soportado v√≠a `src/data/splits.py::get_cv` activ√°ndolo con `cv.kind: time` en `config/params.yaml`; en HPO se respeta el orden temporal si se pasa `--date-col`.
Comprobaci√≥n:
- Flujo principal: `python scripts/run_all.py` genera `data/processed/X_train_engineered.csv` y `X_test_engineered.csv` ya separados temporalmente (train ‚â§2018, test ‚â•2020).
- HPO con CV temporal: define en `config/params.yaml` `cv.kind: time` y ejecuta, por ejemplo:
```bash
python scripts/run_hpo.py --task reg --method grid --fast --date-col 'A√ëO' --out-dir outputs/hpo_reg_time
```
Reconfiguraci√≥n: ajusta a√±os en `config/config.py` (TRAIN_END_YEAR, TEST_START_YEAR, etc.) y n_splits en `config/params.yaml`.

### 8.4 Pr√≥ximos pasos
- UI: exponer en ui/app.py un panel ‚ÄúExperimentos (HPO)‚Äù con controles para m√©todo (grid/bayes), tarea (reg/clf), fast, n_jobs, bayes-iter, y bot√≥n Ejecutar que llame a scripts/run_hpo.py y renderice reports/hpo_summary.md y tablas results.csv.
- UI: a√±adir switch ‚ÄúValidaci√≥n temporal (TimeSeriesSplit)‚Äù que lea cv.kind de config/params.yaml y, en datasets externos, campo para --date-col; mostrar el rango train/test efectivo desde config/config.py.
- Guardado de modelo: tras run_all.py con --with-hpo, persistir modelo final con best_params en models/ (pickle) y mostrar link en UI.
- Trazabilidad: registrar en outputs/metadata/run.json versiones de librer√≠as y m√©todo de HPO usado; mostrarlo en UI como metadata de experimento.
- Reproducibilidad: permitir fijar semilla global desde UI y exponer valor actual (config.hpo.random_state).
- Documentaci√≥n: agregar nota de buenas pr√°cticas (evitar data leakage, usar split temporal) en la secci√≥n de ayuda de la UI.

## 9) Implementaci√≥n EvM5U3

### 9.1 Agrupamiento (Clustering)
Esta implementaci√≥n (HU-CLUST-01) agrega un flujo de an√°lisis no supervisado para explorar patrones en los datos procesados (X_train_engineered). Se aplican KMeans y DBSCAN sobre un subconjunto escalado (y opcionalmente reducido con PCA) para identificar grupos potenciales de programas/modalidades.

Ejecutar flujo principal (solo EDA + preprocesamiento + entrenamiento r√°pido, omitiendo evaluaci√≥n y XAI para acelerar):
```bash
python3 scripts/run_all.py --skip-eval --skip-xai
```

Ejecutar clustering (genera metrics, resumen y gr√°ficos):
```bash
python3 scripts/run_clustering.py --save-plots --pca --max-features 40 --seed 42 --sil-sample 3000 --sample-size 40000
```
Par√°metros clave:
- --save-plots: guarda gr√°ficos de Silhouette (KMeans) y heatmap eps/min_samples (DBSCAN) en reports/.
- --pca: aplica PCA si hay >50 features (reduce a <=10 componentes para velocidad).
- --max-features 40: limita columnas iniciales para reducir dimensionalidad y ruido.
- --seed 42: fija reproducibilidad en submuestreos y algoritmos.
- --sil-sample 3000: submuestreo para calcular Silhouette m√°s r√°pido (si el dataset es grande).
- --sample-size 40000: toma hasta 40k filas para acelerar clustering (si hay m√°s, selecciona aleatoriamente).

Resultados (reports/):
- clustering_results.csv: tabla con algoritmo, par√°metros, silhouette, homogeneity, completeness (estas √∫ltimas NaN si no hay proxy de etiqueta) y tiempo.
- clustering_summary.md: top 3 configuraciones por Silhouette y total de configuraciones evaluadas.
- clustering_kmeans_silhouette.png y clustering_dbscan_eps_grid.png: visualizaci√≥n comparativa de calidad de agrupamiento.
Interpretaci√≥n:
- Silhouette mide separaci√≥n interna de clusters (‚âà0.2 indica estructura d√©bil/moderada; valores negativos se√±alan mala asignaci√≥n).
- DBSCAN eps=0.7 mostr√≥ mejor cohesi√≥n (Silhouette‚âà0.22) frente a KMeans cl√°sico, sugiriendo densidades locales aprovechables.
- Homogeneity/completeness se reportan si existe y_train (proxy); de lo contrario se enfocan en m√©tricas intr√≠nsecas.


### 9.2 Detecci√≥n de Anomal√≠as (Anomaly Detection)
Esta implementaci√≥n (HU-ANOM-01) incorpora algoritmos no supervisados para identificar registros potencialmente at√≠picos en el dataset procesado. Permite se√±alar casos extremos para auditor√≠a, limpieza adicional o generaci√≥n de reglas.

Ejecutar flujo previo m√≠nimo (genera X_train_engineered):
```bash
python3 scripts/run_all.py --skip-eval --skip-xai
```
Ejecutar detecci√≥n de anomal√≠as:
```bash
python3 scripts/run_anomaly_detection.py --save-plots --pca --max-features 40 --seed 42 --sample-size 40000 --contamination 0.05
```
Par√°metros clave:
- --save-plots: guarda barplot de fracci√≥n de anomal√≠as y distribuciones de scores por algoritmo.
- --pca: aplica PCA si >50 columnas para reducir dimensionalidad (<=10 componentes) y acelerar.
- --max-features 40: limita variables iniciales (primeras columnas) para reducir ruido.
- --seed 42: reproducibilidad en submuestreos e inicializaciones.
- --sample-size 40000: submuestrea filas si el dataset es mayor (acelera c√≥mputo en LOF/IsolationForest).
- --contamination 0.05: proporci√≥n esperada de anomal√≠as; usada por IsolationForest, LOF, EllipticEnvelope y OneClassSVM.

Resultados (reports/):
- anomaly_results.csv: resumen por algoritmo (anomaly_fraction observada vs contamination_cfg, estad√≠sticas de score, tiempo).
- anomaly_summary.md: top 3 algoritmos cuya fracci√≥n de anomal√≠as m√°s se aproxima a la contaminaci√≥n objetivo.
- anomaly_fraction_by_algo.png: comparaci√≥n visual de las fracciones detectadas.
- anomaly_scores_<ALGO>.csv / anomaly_scores_dist_<ALGO>.png: scores individuales y su distribuci√≥n para an√°lisis posterior.
Interpretaci√≥n:
- anomaly_fraction cercana a contamination_cfg indica calibraci√≥n adecuada; valores muy altos/bajos sugieren revisar par√°metros.
- Scores m√°s extremos (colas) se√±alan candidatos a inspecci√≥n manual; comparar entre algoritmos reduce falsos positivos.



### Borrar todos los artefactos y ejecutar el flujo completo
ejecuta comando bash:
```bash
bash scripts/run_full_flow.sh
```

Ejecutar paso a paso
```bash
- bash clean.sh
- python3 scripts/run_all.py --with-hpo --hpo-method=grid
- python3 scripts/run_hpo.py --task clf --method grid --fast --out-dir outputs/hpo_clf_fast
- python3 scripts/run_hpo.py --task reg --method grid --fast --out-dir outputs/hpo_reg_fast_opt
- python3 scripts/run_clustering.py --save-plots --pca --max-features 40 --seed 42 --sil-sample 3000 --sample-size 40000
- python3 scripts/run_anomaly_detection.py --save-plots --pca --max-features 40 --seed 42 --sample-size 40000 --contamination 0.05
```