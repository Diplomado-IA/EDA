# ü§ù ONBOARDING - Contexto para Nuevos Miembros

## Para Copilot/IA: Archivo de Instrucciones del Proyecto

Este documento define el **contexto y las instrucciones** que debe entender cualquier agente (humano o IA) que trabaje en este proyecto.

---

## üìå Misi√≥n del Proyecto

**Objetivo General:** Construir un modelo predictivo que clasifique el estado de titulaci√≥n de estudiantes de educaci√≥n superior en Chile (2007-2024).

**Dataset:** `data/raw/TITULADO_2007-2024_web_19_05_2025_E.csv` (173,522 registros, 40 columnas)

---

## üèóÔ∏è Arquitectura Modular

El proyecto utiliza una **arquitectura modular de 5 capas**:

```
1. RAW DATA ‚Üí 2. PREPROCESSING ‚Üí 3. FEATURE ENGINEERING ‚Üí 4. MODELING ‚Üí 5. DEPLOYMENT
   Fase 1       Fase 2.1          Fase 2.2               Fase 3        Fase 4
```

Cada fase tiene su propia documentaci√≥n en `docs/faseX_nombre/`.

---

## üìÅ Estructura de Directorios (SOLO LO NECESARIO)

```
/
‚îú‚îÄ‚îÄ data/raw/                    # Datos originales (NO editar)
‚îÇ   ‚îî‚îÄ‚îÄ TITULADO_2007-2024...csv
‚îú‚îÄ‚îÄ data/processed/              # Datos limpios y features (Fases 2-3)
‚îú‚îÄ‚îÄ notebooks/                   # Jupyter notebooks (Ejecuci√≥n interactiva)
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_Preprocesamiento.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_Feature_Engineering.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 04_Model_Training.ipynb
‚îú‚îÄ‚îÄ src/                         # C√≥digo reutilizable (m√≥dulos)
‚îÇ   ‚îú‚îÄ‚îÄ config.py                # Configuraci√≥n global
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py              # Orquestador principal
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/           # Limpieza de datos
‚îÇ   ‚îú‚îÄ‚îÄ features/                # Ingenier√≠a de features
‚îÇ   ‚îî‚îÄ‚îÄ models/                  # Entrenamiento y evaluaci√≥n
‚îú‚îÄ‚îÄ models/                      # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ production/              # Modelo ganador
‚îÇ   ‚îú‚îÄ‚îÄ trained/                 # Todos los modelos
‚îÇ   ‚îî‚îÄ‚îÄ metadata/                # Logs y specifications
‚îú‚îÄ‚îÄ outputs/                     # Gr√°ficos, reportes, visualizaciones
‚îú‚îÄ‚îÄ ui/                          # Dashboard Streamlit
‚îÇ   ‚îî‚îÄ‚îÄ app.py                   # Interfaz de usuario
‚îú‚îÄ‚îÄ docs/                        # Documentaci√≥n detallada (LEER PRIMERO)
‚îÇ   ‚îú‚îÄ‚îÄ fase0_inicio/            # Requerimientos y onboarding
‚îÇ   ‚îú‚îÄ‚îÄ fase1_eda/               # An√°lisis exploratorio
‚îÇ   ‚îú‚îÄ‚îÄ fase2_preprocesamiento/  # Limpieza
‚îÇ   ‚îú‚îÄ‚îÄ fase2_feature_engineering/ # Features
‚îÇ   ‚îú‚îÄ‚îÄ fase3_modelos/           # Modelado
‚îÇ   ‚îú‚îÄ‚îÄ arquitectura/            # Especificaciones t√©cnicas
‚îÇ   ‚îî‚îÄ‚îÄ integracion/             # Pipeline completo
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias Python
‚îú‚îÄ‚îÄ README.md                    # Este archivo
‚îî‚îÄ‚îÄ .gitignore                   # Archivos ignorados en git
```

**‚ùå NO incluir en ra√≠z:**
- main.py (obsoleto)
- DOCUMENTACION.md (contenido en docs/)
- ESTRUCTURA.md (actualizado en docs/)
- scripts/ (si est√° vac√≠o)

---

## üöÄ Inicio R√°pido (5 minutos)

### Paso 1: Clonar y configurar
```bash
cd /home/anaguirv/ia_diplomado/EDA
source venv/bin/activate  # O crear: python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
```

### Paso 2: Verificar setup
```bash
python -c "
import pandas as pd
df = pd.read_csv('data/raw/TITULADO_2007-2024_web_19_05_2025_E.csv')
print(f'‚úì Datos cargados: {df.shape}')
"
```

### Paso 3: Ver documentaci√≥n de tu fase
```bash
# Reemplaza X con tu fase (0, 1, 2, 3, etc.)
cat docs/faseX_nombre/INDICE.md
```

---

## üìñ Fases del Proyecto

### ‚úÖ FASE 0: INICIO
**Responsables:** Product Manager + Tech Lead  
**Entrega:** Requerimientos y setup  
**Documentaci√≥n:** `docs/fase0_inicio/`  
**Status:** ‚úÖ COMPLETADO

**Qu√© hacer si necesitas info:**
```bash
cat docs/fase0_inicio/QUICK_START.md              # Inicio r√°pido
cat docs/requerimientos_proyecto.md              # Qu√© se pide
cat docs/fase0_inicio/03M5U2_Evaluacion.md       # Evaluaci√≥n del curso
```

---

### ‚úÖ FASE 1: AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)
**Notebook:** `notebooks/01_EDA.ipynb`  
**Documentaci√≥n:** `docs/fase1_eda/INDICE.md`  
**Status:** ‚úÖ COMPLETADO

**Qu√© sali√≥:**
- 40 variables analizadas (tipos de datos, nulos, distribuciones)
- Gr√°ficos de distribuci√≥n en `outputs/`
- Detecci√≥n de outliers y anomal√≠as
- Correlaciones entre variables

**Si necesitas regenerar:**
```bash
jupyter notebook notebooks/01_EDA.ipynb
```

---

### ‚úÖ FASE 2.1: PREPROCESAMIENTO
**Notebook:** `notebooks/02_Preprocesamiento.ipynb`  
**Documentaci√≥n:** `docs/fase2_preprocesamiento/INDICE.md`  
**Status:** ‚úÖ COMPLETADO

**Transformaciones aplicadas:**
- Limpieza de valores nulos
- Manejo de outliers
- Normalizaci√≥n/Escalado
- Encoding de variables categ√≥ricas
- Balanceo de clases (si aplica)

**Salida:** `data/processed/preprocessed_data.csv`

---

### ‚úÖ FASE 2.2: FEATURE ENGINEERING
**Notebook:** `notebooks/03_Feature_Engineering.ipynb`  
**Documentaci√≥n:** `docs/fase2_feature_engineering/INDICE.md`  
**Status:** ‚úÖ COMPLETADO

**Transformaciones aplicadas:**
- Creaci√≥n de variables derivadas (ratios, interacciones)
- Selecci√≥n de features relevantes
- Reducci√≥n dimensional (si es necesario)
- Validaci√≥n de features

**Salida:** `data/processed/final_dataset.csv`  
**M√≥dulo:** `src/features/engineer.py`

---

### üîÑ FASE 3: MODELADO PREDICTIVO
**Notebooks:** `03_MODEL_EVALUATION.ipynb` ‚Üí `04_FINAL_VALIDATION.ipynb`  
**Documentaci√≥n:** `docs/fase3_modelos/HISTORIA_USUARIO_FASE3.md`  
**Status:** üîÑ EN PROGRESO

**Qu√© hacer:**

1. **Lee la especificaci√≥n completa:**
```bash
cat docs/fase3_modelos/HISTORIA_USUARIO_FASE3.md
```

2. **Estructura:**
   - Sprint 1: Entrenar 5 modelos base (LR, RF, GB, SVM, NN)
   - Sprint 2: Evaluar con K-Fold CV, generar reportes comparativos
   - Sprint 3: Seleccionar mejor modelo, validaci√≥n final

3. **Criterios de √âxito:**
   - F1-Score Test > 0.75
   - Recall > 0.70
   - Documentaci√≥n completa en `docs/fase3_modelos/MODELOS_FINALES.md`

4. **Crear notebooks:**
```bash
jupyter notebook notebooks/03_MODEL_EVALUATION.ipynb
jupyter notebook notebooks/04_FINAL_VALIDATION.ipynb
```

---

## üîß Instrucciones T√©cnicas Espec√≠ficas

### C√≥mo ejecutar un notebook
```bash
# Opci√≥n 1: Jupyter interactivo
jupyter notebook notebooks/01_EDA.ipynb

# Opci√≥n 2: Terminal (para testing autom√°tico)
jupyter nbconvert --to notebook --execute notebooks/01_EDA.ipynb
```

### C√≥mo verificar que todo funciona
```bash
# Test del pipeline completo
python -c "
from src.pipeline import MLPipeline
pipeline = MLPipeline()
print('‚úì Pipeline OK')
"

# Test de datos
python -c "
import pandas as pd
from src.preprocessing.preprocessor import Preprocessor
df = pd.read_csv('data/raw/TITULADO_2007-2024_web_19_05_2025_E.csv')
prep = Preprocessor()
clean_df = prep.fit_transform(df)
print(f'‚úì Preprocesamiento OK: {clean_df.shape}')
"
```

### C√≥mo usar la UI
```bash
streamlit run ui/app.py
# Abre en http://localhost:8501
```

---

## üìä Configuraci√≥n Global

Todos los par√°metros globales est√°n en `src/config.py`:

```python
# Rutas de datos
DATA_RAW = 'data/raw/'
DATA_PROCESSED = 'data/processed/'
MODELS_PATH = 'models/production/'

# Par√°metros de modelo
RANDOM_STATE = 42
TEST_SIZE = 0.2
VALIDATION_SIZE = 0.1

# Modelos a entrenar
MODELS_TO_TRAIN = ['LogisticRegression', 'RandomForest', 'GradientBoosting', 'SVM', 'NeuralNetwork']

# Criterios de selecci√≥n
SELECTION_CRITERIA = {
    'f1_score': 0.60,
    'recall': 0.30,
    'latency': 0.10
}
```

Modifica aqu√≠ si necesitas cambiar comportamiento global.

---

## üö® Troubleshooting

### Error: ModuleNotFoundError: No module named 'src'
**Soluci√≥n:**
```bash
cd /home/anaguirv/ia_diplomado/EDA  # Asegurate de estar en la ra√≠z
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### Error: FileNotFoundError: 'data/raw/TITULADO...'
**Soluci√≥n:**
```bash
# Verifica que existe el archivo
ls -la data/raw/
# Si no existe, desc√°rgalo del fuente de datos
```

### Error: 'PROMEDIO EDAD PROGRAMA' no existe
**Soluci√≥n:**
- Verifica el nombre exacto de columnas: `df.columns`
- Algunos notebooks tienen espacios extra. Ajusta el nombre si es necesario

### Error: KeyError en visualizaciones
**Soluci√≥n:**
```bash
# Regenera datos procesados
jupyter nbconvert --to notebook --execute notebooks/02_Preprocesamiento.ipynb
jupyter nbconvert --to notebook --execute notebooks/03_Feature_Engineering.ipynb
```

---

## üìù Checklist para Comenzar

- [ ] Clone/actualice el repo
- [ ] Active el venv: `source venv/bin/activate`
- [ ] Instale dependencias: `pip install -r requirements.txt`
- [ ] Lea `docs/requerimientos_proyecto.md`
- [ ] Identifique su fase de trabajo
- [ ] Lea INDICE.md de su fase
- [ ] Verifique setup: `python -c "import pandas; print('OK')"`
- [ ] Ejecute primer notebook de su fase

---

## üîó Referencias R√°pidas

| Necesito... | Ir a... |
|------------|---------|
| Entender el proyecto | `docs/requerimientos_proyecto.md` |
| Especificaci√≥n t√©cnica | `docs/arquitectura/ARQUITECTURA_MODULAR.md` |
| C√≥mo ejecutar c√≥digo | `docs/arquitectura/GUIA_EJECUCION_MODULAR.md` |
| Qu√© ya se hizo | `docs/integracion/VERIFICACION_README.md` |
| Configuraci√≥n global | `src/config.py` |
| Modelos entrenados | `models/trained/` y `models/production/` |
| Gr√°ficos y reportes | `outputs/` |

---

## üë• Roles y Responsabilidades

- **Data Engineer:** Fase 2.1 (Preprocesamiento) - `src/preprocessing/`
- **Data Scientist:** Fase 1 + 2.2 + 3 (EDA, Features, Modelos)
- **ML Engineer:** Fase 3 (Productivizaci√≥n de modelos)
- **Frontend Dev:** `ui/app.py` (Dashboard Streamlit)

---

## üéì Filosof√≠a del Proyecto

1. **Reproducibilidad:** Seed fijo (42), versiones pinned en requirements.txt
2. **Modularidad:** Cada fase separada, reutilizable
3. **Documentaci√≥n:** Inline comments para c√≥digo complejo, docstrings en funciones
4. **Testing:** Validaciones en cada notebook antes de exportar
5. **Trazabilidad:** Logs de entrenamiento, metadata de modelos

---

## üìû Preguntas Frecuentes

**P: ¬øPor qu√© hay notebooks si tenemos m√≥dulos en src/?**  
A: Los notebooks son para exploraci√≥n e iteraci√≥n r√°pida. El c√≥digo final se refactoriza en src/ para reutilizaci√≥n.

**P: ¬øC√≥mo se ejecuta sin main.py?**  
A: Se ejecuta desde notebooks (interactivo) o `streamlit run ui/app.py` (producci√≥n).

**P: ¬øD√≥nde agrego mis propias features?**  
A: En `src/features/engineer.py`, funci√≥n `create_new_features()`.

**P: ¬øC√≥mo guardo mi modelo?**  
A: Autom√°tico en `models/trained/` desde `src/models/trainer.py`.

---

**√öltima actualizaci√≥n:** 2025-11-12  
**Versi√≥n:** 1.0 - Contexto Completo para Nuevos Miembros
